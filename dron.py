# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oU1rvlS0CAo4iP8QQN4bRJChJJ1ahIy9
"""

from GUI import GUI
from HAL import HAL
import cv2
import argparse
import urllib.request
import math #import tan, atan, radians # cambiarlo
#from pyproj import Proj, transform

angle_increment = 0.1  # Ajusta según tus necesidades
radius_increment = 1  # Ajusta según tus necesidades
max_radius = 30  # Ajusta según tus necesidades
radius=1
rescue_coordinates_list = []
VICTIMS_X = 32
VICTIMS_Y = -40
BOAT_X = 0
BOAT_Y = 0

x_vel = 0.18 #0.25
angle = 0.6
iterations = 0
spiral_iterations = 300
landing_margin = 0.07
x_pos = HAL.get_position()[0]
y_pos = HAL.get_position()[1]
HAL.takeoff(3)


#carga la url en un archivo
url = 'https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_alt2.xml'

# Descargar el archivo
urllib.request.urlretrieve(url, 'haarcascade_frontalface_alt.xml')

# Cargar el clasificador de rostros
face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')

# Verificar si el clasificador de rostros se ha cargado correctamente
if face_cascade.empty():
    print('Error al cargar el clasificador de rostros.')
else:
    print('Clasificador de rostros cargado correctamente.')



def convert_pixel_coordinates_to_utm(drone_y, drone_x):
    #Realizar la conversión de coordenadas del dron a UTM
    utm_norte = drone_x
    utm_este = -drone_y
    print(f"Coordenadas UTM: ({utm_norte}, {utm_este}")
    return utm_norte, utm_este



def detectAndDisplay(frame):
    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    frame_gray = cv2.equalizeHist(frame_gray)


  # Ajustar el tamaño mínimo y máximo según tus necesidades
    minSize = (10, 10) # lo tenia en 10
    maxSize = (300, 300) #300  300
    scaleFactor = 1.1 #1.1
    minNeighbors = 1 #1 era 3 originalmente
    # Detectar rostros con los parámetros ajustados
    faces = face_cascade.detectMultiScale(frame_gray, scaleFactor=scaleFactor, minNeighbors=minNeighbors, minSize=minSize, maxSize=maxSize)

    for (x, y, w, h) in faces:
        center = (x + w // 2, y + h // 2)
        frame = cv2.ellipse(frame, center, (w // 2, h // 2), 0, 0, 360, (255, 0, 255), 4)

        #victim_coordinates = HAL.convert_pixel_coordinates_to_utm(x, y)
        x_pos = HAL.get_position()
        y_pos = HAL.get_position()
        victim_coordinates = convert_pixel_coordinates_to_utm(y_pos,x_pos)
        rescue_coordinates_list.append(victim_coordinates)

    return len(faces) > 0

# se ejecuta cuando no esta cerca de las ubicaciones predetermianda
while not((VICTIMS_X - 1 < x_pos) and (x_pos < VICTIMS_X + 1) and (VICTIMS_Y - 1 < y_pos) and (y_pos < VICTIMS_Y + 1)):

     # Mostrar imágenes en la GUI
    x_pos = HAL.get_position()[0]
    y_pos = HAL.get_position()[1]
    GUI.showImage(HAL.get_ventral_image())
    GUI.showLeftImage(HAL.get_ventral_image())

    # Establecer la posición del dron hacia la víctima
    HAL.set_cmd_pos(VICTIMS_X, VICTIMS_Y, 3, angle) #3

#time.sleep(0.01)


# Resto del código iterativo cuando esta cerca de las ubicacion perdeterminada
while True:

    frontal_image = HAL.get_ventral_image()

    # Convertir la imagen a escala de grises para la detección de rostros
    gray_frontal_image = cv2.cvtColor(frontal_image, cv2.COLOR_BGR2GRAY)

    # Ejecutar la función de detección de rostros
    #detectAndDisplay(frontal_image)
    if detectAndDisplay(frontal_image):
       print("Encontro la persona perdida")
       #print(rescue_coordinates_list)

       for coordinates in rescue_coordinates_list:
            print(f"({coordinates[0]}, {coordinates[1]})")
    angle += angle_increment
    radius += radius_increment
    # Calcular las nuevas coordenadas en espiral
    x_pos = VICTIMS_X + radius * math.cos(angle)
    y_pos = VICTIMS_Y + radius * math.sin(angle)
    HAL.set_cmd_pos(x_pos, y_pos, 3, angle)

    print(x_pos)

    if radius >= max_radius:
            radius = 0  # Reiniciar el radio para una nueva espiral

    GUI.showLeftImage(HAL.get_ventral_image())
    GUI.showImage(HAL.get_frontal_image())